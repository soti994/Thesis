{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Disabling auto-scroll of outputs\n",
    "\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "def set_css():\n",
    "  display(HTML('''\n",
    "  <style>\n",
    "    pre {\n",
    "        white-space: pre-wrap;\n",
    "    }\n",
    "  </style>\n",
    "  '''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "start_time = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import nltk\n",
    "import seaborn as sns\n",
    "import re\n",
    "import string \n",
    "import gensim.downloader as api\n",
    "from autocorrect import Speller\n",
    "from wordcloud import WordCloud\n",
    "from emot.emo_unicode import UNICODE_EMO, EMOTICONS, EMOTICONS_EMO\n",
    "from collections import Counter\n",
    "from num2words import num2words\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.tokenize import word_tokenize,TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from pycontractions import Contractions\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.dates import DateFormatter\n",
    "# Handle date time conversions between pandas and matplotlib\n",
    "#from pandas.plotting import register_matplotlib_converters\n",
    "#register_matplotlib_converters()\n",
    "from cycler import cycler\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "train1 = pd.read_csv(\"Corona_NLP_train.csv\", delimiter=',', encoding= 'ISO-8859-1')\n",
    "test = pd.read_csv(\"Corona_NLP_test.csv\", delimiter=',', encoding= 'ISO-8859-1')\n",
    "#data = [train1, test]\n",
    "\n",
    "#train = pd.concat(data)\n",
    "train= train1\n",
    "#print(train1.isna().sum(), test.isna().sum())\n",
    "print(train1.OriginalTweet.str.isalpha().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Positive              11422\n",
       "Negative               9917\n",
       "Neutral                7713\n",
       "Extremely Positive     6624\n",
       "Extremely Negative     5481\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability a priori for class\t Negative : 0.374\t Neutral : 0.187\t Positive: 0.438\n"
     ]
    }
   ],
   "source": [
    "#\"Extremely Negative\": -1, \"Negative\": -1, \"Neutral\": 0, \"Positive\": 1, \"Extremely Positive\": 1\n",
    "\n",
    "def change_values(string):\n",
    "    if string == \"Extremely Negative\":\n",
    "        return 0\n",
    "    elif string == \"Negative\":\n",
    "        return 0\n",
    "    elif string == \"Positive\":\n",
    "        return 2 \n",
    "    elif string == \"Extremely Positive\":\n",
    "        return 2\n",
    "    elif string == \"Neutral\":\n",
    "        return 1 \n",
    "    \n",
    "train['Sentiment'] = train['Sentiment'].apply(change_values)\n",
    "\n",
    "#Probability\n",
    "n0 = train['Sentiment'].value_counts()[0]\n",
    "n1 = train['Sentiment'].value_counts()[1]\n",
    "n2 = train['Sentiment'].value_counts()[2]\n",
    "n = n0 + n1 +n2\n",
    "\n",
    "p0 = n0 / n\n",
    "p1 = n1 / n \n",
    "p2 = n2 / n\n",
    "\n",
    "print(\"Probability a priori for class\\t Negative : {}\\t Neutral : {}\\t Positive: {}\".format(\n",
    "     round(p0, 3), round(p1, 3), round(p2, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop 'ScreenName', 'Location', 'TweetAt' Columns\n",
    "train = train.drop(['ScreenName', 'TweetAt'], axis=1)\n",
    "#pd.set_option('display.max_colwidth', -1)\n",
    "#print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"date1 = pd.to_datetime(train['TweetAt'], errors='coerce', \\n                       format='%d/%m/%Y')\\ndate2 = pd.to_datetime(train['TweetAt'], errors='coerce',\\n                       format='%d-%m-%Y')\\ntrain['TweetAt'] = date1.fillna(date2)\\nprint (train['TweetAt'])\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print (train['TweetAt'])\n",
    "'''date1 = pd.to_datetime(train['TweetAt'], errors='coerce', \n",
    "                       format='%d/%m/%Y')\n",
    "date2 = pd.to_datetime(train['TweetAt'], errors='coerce',\n",
    "                       format='%d-%m-%Y')\n",
    "train['TweetAt'] = date1.fillna(date2)\n",
    "print (train['TweetAt'])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Counter columns\n",
    "\n",
    "#train['count_sentences']=train['OriginalTweet'].str.count('[\\w][\\.!\\?]').clip(lower=1)\n",
    "train['count_words'] = train['OriginalTweet'].apply(lambda x: \n",
    "                                    len(str(x).split()))\n",
    "train['count_unique_words'] = train['OriginalTweet'].apply(lambda x: \n",
    "                                    len(set(str(x).split())))\n",
    "train['count_letters'] = train['OriginalTweet'].apply(lambda x: \n",
    "                                    len(str(x)))\n",
    "train['count_stopwords'] = train['OriginalTweet'].apply(lambda x: \n",
    "        len([w for w in str(x).lower().split() if w in stop_words]))\n",
    "train['mean_word_len'] = train['OriginalTweet'].apply(lambda x: \n",
    "                        np.mean([len(w) for w in str(x).split()]))\n",
    "train['count_mentions'] = train['OriginalTweet'].str.findall(\n",
    "                 r'(?<=^|(?<=[^a-zA-Z0-9-_\\.]))@([A-Za-z]+[A-Za-z0-9-_]+)').str.len()\n",
    "train['count_hashtags'] = train['OriginalTweet'].str.findall(\n",
    "                        r'#([A-Za-z0-9_]+)').str.len()\n",
    "train['count_words_upper'] = train['OriginalTweet'].apply(lambda x: \n",
    "                    len([w for w in str(x).split() if w.isupper()]))\n",
    "train['count_words_title'] = train['OriginalTweet'].apply(lambda x: \n",
    "                    len([w for w in str(x).split() if w.istitle()]))\n",
    "train['count_excl_quest_marks'] = train['OriginalTweet'].str.findall(\n",
    "                        r'(!|\\?)').str.len()\n",
    "train['count_urls'] = train['OriginalTweet'].str.findall(\n",
    "                        r'http\\S+|www\\S+|https\\S+').str.len()\n",
    "\n",
    "#print(train['count_sentences'].head(20))\n",
    "#punctuation count\n",
    "#twitter_data[\"count_punctuations\"] =twitter_data[\"full_text\"].apply(lambda x: len([c for c in str(x) if c in string.punctuation]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2c8bbe7e488>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot word count distribution for positive, neutral and negative sentiments\n",
    "x = train['count_words'][train.Sentiment == 0]\n",
    "y = train['count_words'][train.Sentiment == 1]\n",
    "z = train['count_words'][train.Sentiment == 2]\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.xlim(0,45)\n",
    "plt.xlabel('word count')\n",
    "plt.ylabel('frequency')\n",
    "g = plt.hist([x, y, z], color=['r','b', 'g'], alpha=0.5, label=['negative', 'neutral', 'positive'])\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My food stock is not the only one which is empty...\r",
      "\r\n",
      "\r",
      "\r\n",
      "PLEASE, don't panic, THERE WILL BE ENOUGH FOOD FOR EVERYONE if you do not take more than you need. \r",
      "\r\n",
      "Stay calm, stay safe.\r",
      "\r\n",
      "\r",
      "\r\n",
      "#COVID19france #COVID_19 #COVID19 #coronavirus #confinement #Confinementotal #ConfinementGeneral https://t.co/zrlG0Z520j\n"
     ]
    }
   ],
   "source": [
    "#&amp; removal to and\n",
    "train['EditedTweet'] = train['OriginalTweet'].replace(\n",
    "                r'&amp;', ' and ', regex=True)\n",
    "train['EditedTweet'] = train['EditedTweet'].replace(\n",
    "                r'&lt;', ' ', regex=True)\n",
    "train['EditedTweet'] = train['EditedTweet'].replace(\n",
    "                r'&gt;', ' ', regex=True)\n",
    "print(train['EditedTweet'][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@TinaMcCauley70 Yeah my parents are risky people to the covid 19 thats why we stay at home just go to the supermarket when really necessary.. stay safe too ....\n",
      "Food banks forced to close amid coronavirus outbreak https://t.co/ChGUNZPP4W Independent #Corona #wiwt #Covid19 #friday #update #who #tbt\n"
     ]
    }
   ],
   "source": [
    "#non-ASCII character removal\n",
    "#train['EditedTweet'] = train['OriginalTweet'].replace(\n",
    " #               r'Ã‚Â', \"'\", regex=True)\n",
    "train['EditedTweet'] = train['EditedTweet'].str.encode('ascii', \n",
    "                            'ignore').str.decode('ascii')\n",
    "print(train['EditedTweet'][68])\n",
    "print(train['EditedTweet'][2098])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@MeNyrbie @Phil_Gahan @Chrisitv  <url>  and  <url>  and  <url> \n"
     ]
    }
   ],
   "source": [
    "#Link replacement\n",
    "train['EditedTweet'] = train['EditedTweet'].replace(\n",
    "                r'http\\S+|www\\S+|https\\S+', ' <url> ', regex=True)\n",
    "print(train['EditedTweet'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " <user>   <user>   <user>   <url>  and  <url>  and  <url> \n"
     ]
    }
   ],
   "source": [
    "#Mention replacement (with e-mail handling)\n",
    "train['EditedTweet'] = train['EditedTweet'].replace(\n",
    "    r'(?<=^|(?<=[^a-zA-Z0-9-_\\.]))@([A-Za-z]+[A-Za-z0-9-_]+)', ' <user> ', regex=True)\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "print(train['EditedTweet'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   UserName Location  \\\n",
      "3  3802      NaN       \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                       OriginalTweet  \\\n",
      "3  My food stock is not the only one which is empty...\\r\\r\\n\\r\\r\\nPLEASE, don't panic, THERE WILL BE ENOUGH FOOD FOR EVERYONE if you do not take more than you need. \\r\\r\\nStay calm, stay safe.\\r\\r\\n\\r\\r\\n#COVID19france #COVID_19 #COVID19 #coronavirus #confinement #Confinementotal #ConfinementGeneral https://t.co/zrlG0Z520j   \n",
      "\n",
      "   Sentiment  count_words  count_unique_words  count_letters  count_stopwords  \\\n",
      "3  2          42           39                  306            19                \n",
      "\n",
      "   mean_word_len  count_mentions  count_hashtags  count_words_upper  \\\n",
      "3  6.0            0               7               10                  \n",
      "\n",
      "   count_words_title  count_excl_quest_marks  count_urls  \\\n",
      "3  3                  0                       1            \n",
      "\n",
      "                                                                                                                                                                                                                                                                                            EditedTweet  \n",
      "3  My food stock is not the only one which is empty...\\r\\r\\n\\r\\r\\nPLEASE, don't panic, THERE WILL BE ENOUGH FOOD FOR EVERYONE if you do not take more than you need. \\r\\r\\nStay calm, stay safe.\\r\\r\\n\\r\\r\\n <hashtag>   <hashtag>   <hashtag>   <hashtag>   <hashtag>   <hashtag>   <hashtag>   <url>   \n"
     ]
    }
   ],
   "source": [
    "#Hashtag replacement\n",
    "train['EditedTweet'] = train['EditedTweet'].replace(\n",
    "    r'#([A-Za-z0-9_]+)', ' <hashtag> ', regex=True)\n",
    "#    r'([#])','', regex=True)\n",
    "print(train[train['UserName']==3802])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Due to COVID-19 our retail store and classroom in Atlanta will not be open for walk-in business or classes for the next two weeks, beginning Monday, March 16.  We will continue to process online and phone orders as normal! Thank you for your understanding!  <url> \n"
     ]
    }
   ],
   "source": [
    "#removal of more of two consequtive characters\n",
    "train['EditedTweet'] = train['EditedTweet'].str.replace(r'(.)\\1+', r'\\1\\1')\n",
    "print(train['EditedTweet'][8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'EMOTICONS = {k: v for (k, v) in EMOTICONS.items() if v != \\'Confusion\\'}\\n\\n# Converting emojis to words\\ndef convert_emojis(text):\\n    for emot in UNICODE_EMO:\\n        text = text.replace(emot, \"_\".join(UNICODE_EMO[emot].replace(\\n                \",\",\"\").replace(\":\",\"\").split()))\\n    return text\\n    \\n# Converting emoticons to words    \\ndef convert_emoticons(text):\\n    for emot in EMOTICONS:\\n        text = re.sub(u\\'(\\'+emot+\\')\\', \"\".join(EMOTICONS[emot].replace(\\n                \",\",\"\").split()), text)\\n    return text\\n\\n# Passing both functions to \\'EditedTweet\\'\\ntrain[\\'EditedTweet\\'] = train[\\'EditedTweet\\'].apply(convert_emoticons)\\ntrain[\\'EditedTweet\\'] = train[\\'EditedTweet\\'].apply(convert_emojis)\\nprint(train[\\'EditedTweet\\'][0])'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''EMOTICONS = {k: v for (k, v) in EMOTICONS.items() if v != 'Confusion'}\n",
    "\n",
    "# Converting emojis to words\n",
    "def convert_emojis(text):\n",
    "    for emot in UNICODE_EMO:\n",
    "        text = text.replace(emot, \"_\".join(UNICODE_EMO[emot].replace(\n",
    "                \",\",\"\").replace(\":\",\"\").split()))\n",
    "    return text\n",
    "    \n",
    "# Converting emoticons to words    \n",
    "def convert_emoticons(text):\n",
    "    for emot in EMOTICONS:\n",
    "        text = re.sub(u'('+emot+')', \"\".join(EMOTICONS[emot].replace(\n",
    "                \",\",\"\").split()), text)\n",
    "    return text\n",
    "\n",
    "# Passing both functions to 'EditedTweet'\n",
    "train['EditedTweet'] = train['EditedTweet'].apply(convert_emoticons)\n",
    "train['EditedTweet'] = train['EditedTweet'].apply(convert_emojis)\n",
    "print(train['EditedTweet'][0])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Due to COVID-19 our retail store and classroom in Atlanta will not be open for walk-in business or classes for the next two weeks, beginning Monday, March 16.  We will continue to process online and phone orders as normal! Thank you for your understanding!  <url> \n"
     ]
    }
   ],
   "source": [
    "#Contraction correction ex. wouldn't->would not \n",
    "\n",
    "#download the model we will use\n",
    "model = api.load(\"glove-twitter-25\")\n",
    "cont = Contractions(kv_model=model)\n",
    "train['EditedTweet'] = list(cont.expand_texts(train['EditedTweet'],precise=True))\n",
    "print(train['EditedTweet'][8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number replacement\n",
    "train['EditedTweet'] = train['EditedTweet'].str.replace(\n",
    "   #  '(\\d+(\\.\\d+)?)|(\\d+(\\,\\d+)?)', r' <number> ') #add space \n",
    "    '(\\d+\\.\\d+)|(\\d+(\\,\\d+)*)', r' <number> ')\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<user> <user> <user> <user> <user> <user> <user> This is both disgusting and disgraceful charging over inflated prices for items for stopping the spread of COVID- <number> , the government really needs to do something abou\n",
      "Due to COVID- <number> our retail store and classroom in Atlanta will not be open for walk-in business or classes for the next two weeks, beginning Monday, March <number> . We will continue to process online and phone orders as normal! Thank you for your understanding! <url>\n",
      "San Francisco. Line to get in to a grocery store. does not open until <number> pm Eastern. This is day one of <hashtag> and do not stand closer than <number> feet apart. <hashtag> <hashtag> <hashtag> <hashtag> <url>\n"
     ]
    }
   ],
   "source": [
    "abbr_dict={\n",
    "    \"lol\":\"laughing out loud\",\n",
    "    \"mkt\":\"market\",\n",
    "    \"diy\":\"do it yourself\",\n",
    "    \"u\":\"you\",\n",
    "    \"gonna\":\"going to\",\n",
    "    \"fav\":\"favorite\",\n",
    "    \"btw\":\"by the way\",\n",
    "    \"omg\":\"oh my god\",\n",
    "    \"n\":\"and\",\n",
    "    \"ppl\":\"people\",\n",
    "    \"tv\":\"television\",\n",
    "    \"ya\":\"yeah\",\n",
    "    \"r\":\"are\",\n",
    "    \"o\":\"oh\",\n",
    "    \"pics\":\"pictures\",\n",
    "    \"pic\":\"picture\",\n",
    "    \" RT \":\"retweet\",\n",
    "    \"wtf\":\"what the fuck\",\n",
    "    \"wanna\":\"want to\",\n",
    "    \"kinda\":\"kind of\",\n",
    "    \"ok\":\"okay\",\n",
    "    \"ur\":\"your\",\n",
    "    \"ya\":\"yeah\",\n",
    "    \"pls\":\"please\",\n",
    "    \"bc\": \"because\",\n",
    "    \"fyi\": \"for your information\",\n",
    "    \"dm\": \"direct message\",\n",
    "    \"soo\": \"so\",\n",
    "    \"Soo\": \"so\",\n",
    "    \":)\": \"<smile>\",\n",
    "    \":-)\": \"<smile>\",\n",
    "    \";)\": \"<smile>\",\n",
    "    \";-)\": \"<smile>\",\n",
    "    \":(\": \"<sadface>\",\n",
    "    \":-(\": \"<sadface>\",\n",
    "    \":'(\": \"<sadface>\",\n",
    " \n",
    "}\n",
    "\n",
    "train['EditedTweet'] = train['EditedTweet'].apply(\n",
    "    lambda x: ' '.join([abbr_dict.get(e, e) for e in x.split()]))\n",
    "\n",
    "print(train['EditedTweet'][78])\n",
    "print(train['EditedTweet'][8])\n",
    "print(train['EditedTweet'][2053])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     UserName       Location  \\\n",
      "236  4035      San Diego, CA   \n",
      "\n",
      "                                                                                                                                                                                                                                                    OriginalTweet  \\\n",
      "236  What's a good way to support grocery store, medical, and hospital staff during this time? I would normally think of something along the lines of ordering everyone pizza, but that doesn't seem like a great idea about now... #COVID2019 #COVID19 #COVID?19   \n",
      "\n",
      "     Sentiment  count_words  count_unique_words  count_letters  \\\n",
      "236  2          41           39                  252             \n",
      "\n",
      "     count_stopwords  mean_word_len  count_mentions  count_hashtags  \\\n",
      "236  14               5.170732       0               3                \n",
      "\n",
      "     count_words_upper  count_words_title  count_excl_quest_marks  count_urls  \\\n",
      "236  4                  1                  2                       0            \n",
      "\n",
      "                                                                                                                                                                                                                                                                  EditedTweet  \n",
      "236  what is a good way to support grocery store, medical, and hospital staff during this time? I would normally think of something along the lines of ordering everyone pizza, but that does not seem like a great idea about now.. <hashtag> <hashtag> <hashtag> ? <number>  \n",
      "<user> <user> <user> <user> <user> <user> <user> This is both disgusting and disgraceful charging over inflated prices for items for stopping the spread of COVID  <number> , the government really needs to do something abou\n",
      "Due to COVID  <number> our retail store and classroom in Atlanta will not be open for walk in business or classes for the next two weeks, beginning Monday, March <number> . We will continue to process online and phone orders as normal! Thank you for your understanding! <url>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#if tweet starts with \".\", start sentence with the next character \n",
    "train['EditedTweet'] = train['EditedTweet'].apply(\n",
    "    lambda x : x[1:] if x.startswith(\".\") else x)\n",
    "\n",
    "#train['EditedTweet'] = train['EditedTweet'].str.replace(\n",
    "#    r'([!\"\\$%&()*+,.\\/:;=#@?\\[\\\\\\]^_`{|}~]+)', r' \\1 ', regex=True)\n",
    "\n",
    "train['EditedTweet'] = train['EditedTweet'].str.replace(\n",
    "    r'([\\-])',r' ', regex=True)\n",
    "\n",
    "\n",
    "print(train[train['UserName']==4035])\n",
    "\n",
    "'''#Punctuation removal\n",
    "\n",
    "RE_PUNCTUATION = '|'.join([re.escape(x) for x in string.punctuation])\n",
    "train[\"EditedTweet\"] = train['EditedTweet'].str.replace(RE_PUNCTUATION, \" \")'''\n",
    "print(train['EditedTweet'][78])\n",
    "print(train['EditedTweet'][8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<user> <user> <user> <url> and <url> and <url>\n"
     ]
    }
   ],
   "source": [
    "#Redundant space removal \n",
    "train['EditedTweet'] = train['EditedTweet'].replace('\\s+', ' ', regex=True)\n",
    "print(train['EditedTweet'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Due to COVID <number> our retail store and classroom in Atlanta will not be open for walk in business or classes for the next two weeks, beginning Monday, March <number> . We will continue to process online and phone orders as normal! Thank you for your understanding! <url>\n"
     ]
    }
   ],
   "source": [
    "#auto-correct tweets \n",
    "#from textblob import TextBlob\n",
    "\n",
    "check = Speller(lang='en')\n",
    "train['EditedTweet'] = [' '.join([check(i) for i in x.split()]) for x in train['EditedTweet']]\n",
    "#train['EditedTweet'] = train['EditedTweet'].apply(lambda x: ''.join(TextBlob(x).correct()))\n",
    "#TextBlob(line).correct()\n",
    "print(train['EditedTweet'][8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lowercase\n",
    "train['EditedTweet'] = train['EditedTweet'].str.lower()\n",
    "#print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     UserName       Location  \\\n",
      "236  4035      San Diego, CA   \n",
      "\n",
      "                                                                                                                                                                                                                                                    OriginalTweet  \\\n",
      "236  What's a good way to support grocery store, medical, and hospital staff during this time? I would normally think of something along the lines of ordering everyone pizza, but that doesn't seem like a great idea about now... #COVID2019 #COVID19 #COVID?19   \n",
      "\n",
      "     Sentiment  count_words  count_unique_words  count_letters  \\\n",
      "236  2          41           39                  252             \n",
      "\n",
      "     count_stopwords  mean_word_len  count_mentions  count_hashtags  \\\n",
      "236  14               5.170732       0               3                \n",
      "\n",
      "     count_words_upper  count_words_title  count_excl_quest_marks  count_urls  \\\n",
      "236  4                  1                  2                       0            \n",
      "\n",
      "                                                                                                                                                                                                                                                                  EditedTweet  \\\n",
      "236  what is a good way to support grocery store, medical, and hospital staff during this time? i would normally think of something along the lines of ordering everyone pizza, but that does not seem like a great idea about now.. <hashtag> <hashtag> <hashtag> ? <number>   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    pos_tagged_sent  \n",
      "236  [(what, WP), (is, VBZ), (a, DT), (good, JJ), (way, NN), (to, TO), (support, VB), (grocery, NN), (store, NN), (,, ,), (medical, JJ), (,, ,), (and, CC), (hospital, JJ), (staff, NN), (during, IN), (this, DT), (time, NN), (?, .), (i, NN), (would, MD), (normally, RB), (think, VB), (of, IN), (something, NN), (along, IN), (the, DT), (lines, NNS), (of, IN), (ordering, VBG), (everyone, NN), (pizza, NN), (,, ,), (but, CC), (that, IN), (does, VBZ), (not, RB), (seem, VB), (like, IN), (a, DT), (great, JJ), (idea, NN), (about, RB), (now, RB), (.., JJ), (<hashtag>, NNP), (<hashtag>, NNP), (<hashtag>, NNP), (?, .), (<number>, NN)]  \n"
     ]
    }
   ],
   "source": [
    "#Column of POS Tagged Sentences\n",
    "tweet_tokenizer = TweetTokenizer()\n",
    "train['pos_tagged_sent'] = train['EditedTweet'].apply(lambda x: \n",
    "                                    pos_tag(tweet_tokenizer.tokenize(x)))\n",
    "print(train[train['UserName']==4035])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        JJ  NNP   CC   VB    NN   TO  PRP$  NNS  VBP   IN  ...  EX  ''  JJS  \\\n",
      "0      1.0  4.0  2.0  1.0 NaN   NaN  NaN   NaN  NaN  NaN   ... NaN NaN NaN    \n",
      "1      6.0 NaN   1.0  1.0  9.0   2.0  1.0   8.0  2.0  5.0  ... NaN NaN NaN    \n",
      "2      2.0  1.0 NaN   1.0  4.0   1.0 NaN    3.0 NaN   1.0  ... NaN NaN NaN    \n",
      "3      9.0  4.0  1.0  3.0  7.0  NaN   1.0  NaN   3.0  3.0  ... NaN NaN NaN    \n",
      "4      5.0  5.0  2.0  2.0  10.0  1.0  1.0  NaN   2.0  4.0  ... NaN NaN NaN    \n",
      "...    ...  ...  ...  ...   ...  ...  ...   ..   ...  ...  ...  ..  ..  ..    \n",
      "41152  1.0  3.0 NaN  NaN   4.0   1.0 NaN    2.0 NaN   1.0  ... NaN NaN NaN    \n",
      "41153  3.0  1.0 NaN   2.0  4.0   2.0 NaN    1.0 NaN   3.0  ... NaN NaN NaN    \n",
      "41154  2.0  4.0 NaN   1.0  2.0  NaN   1.0  NaN   1.0 NaN   ... NaN NaN NaN    \n",
      "41155  2.0 NaN  NaN   1.0  5.0   1.0 NaN   NaN  NaN   3.0  ... NaN NaN NaN    \n",
      "41156  4.0 NaN   1.0 NaN   13.0  1.0 NaN    2.0  2.0  7.0  ... NaN NaN NaN    \n",
      "\n",
      "       UH  FW    $  RBS  WP$  SYM  ``  \n",
      "0     NaN NaN NaN  NaN  NaN  NaN  NaN  \n",
      "1     NaN NaN NaN  NaN  NaN  NaN  NaN  \n",
      "2     NaN NaN NaN  NaN  NaN  NaN  NaN  \n",
      "3     NaN NaN NaN  NaN  NaN  NaN  NaN  \n",
      "4     NaN NaN NaN  NaN  NaN  NaN  NaN  \n",
      "...    ..  ..  ..   ..   ..   ..   ..  \n",
      "41152 NaN NaN NaN  NaN  NaN  NaN  NaN  \n",
      "41153 NaN NaN NaN  NaN  NaN  NaN  NaN  \n",
      "41154 NaN NaN NaN  NaN  NaN  NaN  NaN  \n",
      "41155 NaN NaN NaN  NaN  NaN  NaN  NaN  \n",
      "41156 NaN NaN  2.0 NaN  NaN  NaN  NaN  \n",
      "\n",
      "[41157 rows x 44 columns]\n",
      "     UserName       Location  \\\n",
      "236  4035      San Diego, CA   \n",
      "\n",
      "                                                                                                                                                                                                                                                    OriginalTweet  \\\n",
      "236  What's a good way to support grocery store, medical, and hospital staff during this time? I would normally think of something along the lines of ordering everyone pizza, but that doesn't seem like a great idea about now... #COVID2019 #COVID19 #COVID?19   \n",
      "\n",
      "     Sentiment  count_words  count_unique_words  count_letters  \\\n",
      "236  2          41           39                  252             \n",
      "\n",
      "     count_stopwords  mean_word_len  count_mentions  count_hashtags  \\\n",
      "236  14               5.170732       0               3                \n",
      "\n",
      "     count_words_upper  count_words_title  count_excl_quest_marks  count_urls  \\\n",
      "236  4                  1                  2                       0            \n",
      "\n",
      "                                                                                                                                                                                                                                                                  EditedTweet  \\\n",
      "236  what is a good way to support grocery store, medical, and hospital staff during this time? i would normally think of something along the lines of ordering everyone pizza, but that does not seem like a great idea about now.. <hashtag> <hashtag> <hashtag> ? <number>   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    pos_tagged_sent  \n",
      "236  [(what, WP), (is, VBZ), (a, DT), (good, JJ), (way, NN), (to, TO), (support, VB), (grocery, NN), (store, NN), (,, ,), (medical, JJ), (,, ,), (and, CC), (hospital, JJ), (staff, NN), (during, IN), (this, DT), (time, NN), (?, .), (i, NN), (would, MD), (normally, RB), (think, VB), (of, IN), (something, NN), (along, IN), (the, DT), (lines, NNS), (of, IN), (ordering, VBG), (everyone, NN), (pizza, NN), (,, ,), (but, CC), (that, IN), (does, VBZ), (not, RB), (seem, VB), (like, IN), (a, DT), (great, JJ), (idea, NN), (about, RB), (now, RB), (.., JJ), (<hashtag>, NNP), (<hashtag>, NNP), (<hashtag>, NNP), (?, .), (<number>, NN)]  \n"
     ]
    }
   ],
   "source": [
    "pos_counts =  pd.DataFrame(train['pos_tagged_sent'].map(lambda x: \n",
    "                                    Counter(tag[1] for tag in x)).to_list())\n",
    "print(pos_counts)\n",
    "print(train[train['UserName']==4035])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        [(<user>, a), (<user>, n), (<user>, n), (<url>, n), (and, ), (<url>, n), (and, ), (<url>, v)]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
      "1        [(advice, n), (talk, n), (to, ), (your, ), (neighbours, n), (family, n), (to, ), (exchange, v), (phone, n), (numbers, n), (create, v), (contact, a), (list, n), (with, ), (phone, n), (numbers, n), (of, ), (neighbours, n), (schools, n), (employer, v), (chemist, a), (gt, n), (set, v), (up, r), (online, a), (shopping, n), (accounts, n), (if, ), (pos, a), (adequate, a), (supplies, n), (of, ), (regular, a), (mens, n), (but, ), (not, r), (over, ), (order, n)]                                                                                                                \n",
      "2        [(coronavirus, n), (australia, n), (:, ), (woolworths, n), (to, ), (give, v), (elderly, a), (,, ), (disabled, v), (dedicated, v), (shopping, n), (hours, n), (amid, ), (covid, a), (<number>, n), (outbreak, n), (<url>, n)]                                                                                                                                                                                                                                                                                                                                                            \n",
      "3        [(my, ), (food, n), (stock, n), (is, v), (not, r), (the, ), (only, a), (one, ), (which, ), (is, v), (empty, a), (.., a), (please, n), (,, ), (do, v), (not, r), (panic, v), (,, ), (here, r), (will, ), (by, ), (enough, a), (od, n), (or, ), (everyone, n), (if, ), (you, ), (do, v), (not, r), (take, v), (more, a), (than, ), (you, ), (need, v), (., ), (stay, v), (calm, a), (,, ), (stay, a), (safe, a), (., ), (<hashtag>, a), (<hashtag>, a), (<hashtag>, n), (<hashtag>, n), (<hashtag>, n), (<hashtag>, n), (<hashtag>, n), (<url>, n)]                                       \n",
      "4        [(me, ), (,, ), (ready, a), (to, ), (go, v), (at, ), (supermarket, n), (during, ), (the, ), (<hashtag>, n), (outbreak, n), (., ), (not, r), (because, ), (i, n), (am, v), (paranoid, n), (,, ), (but, ), (because, ), (my, ), (food, n), (stock, n), (is, v), (literary, a), (empty, r), (., ), (the, ), (<hashtag>, n), (is, v), (a, ), (serious, a), (thing, n), (,, ), (but, ), (please, n), (,, ), (do, v), (not, r), (panic, v), (., ), (it, ), (causes, v), (shortage, a), (.., a), (<hashtag>, n), (<hashtag>, n), (<hashtag>, n), (<hashtag>, n), (<url>, n)]                   \n",
      "                                                                                                                                                                                                                                                                                         ...                                                                                                                                                                                                                                                                                                     \n",
      "41152    [(airline, n), (pilots, n), (offering, v), (to, ), (stock, n), (supermarket, n), (shelves, n), (in, ), (<hashtag>, n), (lockdown, a), (<hashtag>, n), (<number>, n), (<url>, n)]                                                                                                                                                                                                                                                                                                                                                                                                        \n",
      "41153    [(response, n), (to, ), (complaint, v), (not, r), (provided, v), (citing, v), (covid, a), (<number>, n), (related, a), (delays, n), (., ), (yet, r), (prompt, a), (in, ), (rejecting, v), (policy, n), (before, ), (consumer, n), (at, ), (is, v), (over, r), (., ), (way, n), (to, ), (go, v), (?, )]                                                                                                                                                                                                                                                                                  \n",
      "41154    [(you, ), (know, v), (its, ), (getting, v), (tough, a), (when, ), (<user>, n), (is, v), (rationing, v), (toilet, a), (paper, n), (<hashtag>, n), (<hashtag>, n), (<user>, n), (martinsville, n), (,, ), (help, v), (us, ), (out, r), (!, ), (!, )]                                                                                                                                                                                                                                                                                                                                      \n",
      "41155    [(is, v), (it, ), (wrong, a), (that, ), (the, ), (smell, n), (of, ), (hand, n), (sanitizer, n), (is, v), (starting, v), (to, ), (turn, v), (me, ), (on, ), (?, ), (<hashtag>, a), (<hashtag>, n), (<hashtag>, n)]                                                                                                                                                                                                                                                                                                                                                                       \n",
      "41156    [(<user>, r), (well, r), (new, a), (/, n), (used, v), (rift, n), (s, n), (are, v), (going, v), (for, ), ($, ), (<number>, ), (on, ), (amazon, n), (rn, n), (although, ), (the, ), (normal, a), (market, n), (price, n), (is, v), (usually, r), ($, ), (<number>, n), (., ), (prices, n), (are, v), (really, r), (crazy, a), (right, n), (now, r), (for, ), (vr, n), (headset, n), (since, ), (l, n), (alex, n), (was, v), (announced, v), (and, ), (it, ), (is, v), (only, r), (been, v), (worse, a), (with, ), (covid, a), (<number>, n), (., ), (up, r), (to, ), (you, ), (whether, )]\n",
      "Name: Wordnet_tagged_sent, Length: 41157, dtype: object\n",
      "0        <user> <user> <user> <url> and <url> and <url>                                                                                                                                                                                                                             \n",
      "1        advice talk to your neighbour family to exchange phone number create contact list with phone number of neighbour school employer chemist gt set up online shopping account if pos adequate supply of regular men but not over order                                        \n",
      "2        coronavirus australia : woolworth to give elderly , disable dedicate shopping hour amid covid <number> outbreak <url>                                                                                                                                                      \n",
      "3        my food stock be not the only one which be empty .. please , do not panic , here will by enough od or everyone if you do not take more than you need . stay calm , stay safe . <hashtag> <hashtag> <hashtag> <hashtag> <hashtag> <hashtag> <hashtag> <url>                 \n",
      "4        me , ready to go at supermarket during the <hashtag> outbreak . not because i be paranoid , but because my food stock be literary empty . the <hashtag> be a serious thing , but please , do not panic . it cause shortage .. <hashtag> <hashtag> <hashtag> <hashtag> <url>\n",
      "                                                                                                                                            ...                                                                                                                                     \n",
      "41152    airline pilot offer to stock supermarket shelf in <hashtag> lockdown <hashtag> <number> <url>                                                                                                                                                                              \n",
      "41153    response to complaint not provide cite covid <number> related delay . yet prompt in reject policy before consumer at be over . way to go ?                                                                                                                                 \n",
      "41154    you know its get tough when <user> be ration toilet paper <hashtag> <hashtag> <user> martinsville , help us out ! !                                                                                                                                                        \n",
      "41155    be it wrong that the smell of hand sanitizer be start to turn me on ? <hashtag> <hashtag> <hashtag>                                                                                                                                                                        \n",
      "41156    <user> well new / use rift s be go for $ <number> on amazon rn although the normal market price be usually $ <number> . price be really crazy right now for vr headset since l alex be announce and it be only be bad with covid <number> . up to you whether              \n",
      "Name: Preprocessed_sentences, Length: 41157, dtype: object\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          a     n          v    r\n",
      "0      1.0   4.0   2.0   1.0 NaN \n",
      "1      6.0   17.0  9.0   4.0  2.0\n",
      "2      2.0   8.0   4.0   3.0 NaN \n",
      "3      10.0  11.0  16.0  8.0  4.0\n",
      "4      5.0   15.0  20.0  7.0  3.0\n",
      "...    ...    ...   ...  ...  ...\n",
      "41152  1.0   9.0   2.0   1.0 NaN \n",
      "41153  3.0   6.0   8.0   6.0  3.0\n",
      "41154  2.0   6.0   7.0   5.0  1.0\n",
      "41155  2.0   5.0   8.0   4.0 NaN \n",
      "41156  5.0   15.0  17.0  9.0  7.0\n",
      "\n",
      "[41157 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# POS tags to WordNet tags\n",
    "def nltk_tag_to_wordnet_tag(nltk_tag):\n",
    "    if nltk_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return \"\"\n",
    "    \n",
    "\n",
    "train['Wordnet_tagged_sent'] = train['pos_tagged_sent'].apply(lambda x : \n",
    "                    [(w,nltk_tag_to_wordnet_tag(t)) for (w, t) in x],1)\n",
    "print (train['Wordnet_tagged_sent'])\n",
    "\n",
    "def lemmatize_sentence(sentence):\n",
    "    lemmatized_sentence = []\n",
    "    for word, tag in sentence:\n",
    "        if tag is \"\":\n",
    "            #if there is no available tag, append the token as is\n",
    "            lemmatized_sentence.append(word)\n",
    "        else:\n",
    "            #else use the tag to lemmatize the token\n",
    "            lemmatized_sentence.append(lemmatizer.lemmatize(word, tag))\n",
    "    return \" \".join(lemmatized_sentence)\n",
    "\n",
    "# Lemmatizing\n",
    "train['Preprocessed_sentences'] = train['Wordnet_tagged_sent'].apply(\n",
    "    lambda x: lemmatize_sentence(x))\n",
    "print (train['Preprocessed_sentences'])\n",
    "\n",
    "wordnet_counts =  pd.DataFrame(train['Wordnet_tagged_sent'].map(lambda x: \n",
    "                                    Counter(tag[1] for tag in x)).to_list())\n",
    "train = pd.concat([train, wordnet_counts], axis=1).fillna(0)\n",
    "print (wordnet_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Renaming new columns\n",
    "#train.rename(columns={ train.columns[7]: 'Other' }, inplace = True)\n",
    "train.rename(columns={'' : 'Others', 'n': 'Nouns', 'v': 'Verbs', \n",
    "            'a': 'Adjectives', 'r': 'Adverbs'}, inplace=True)\n",
    "\n",
    "cols = [\"Others\",\"Nouns\",\"Verbs\",\"Adjectives\",\"Adverbs\"]\n",
    "train[cols] = train[cols].values.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nprint(train['Lemmatize'])\\n\\ntrain['Preprocessed_sentences'] = train.apply(lambda row: \\n                        tweet_tokenizer.tokenize(row['Lemmatize']), axis=1)\\n#print(train['tokenized'])\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tokenization of the lemmatized rows\n",
    "'''\n",
    "print(train['Lemmatize'])\n",
    "\n",
    "train['Preprocessed_sentences'] = train.apply(lambda row: \n",
    "                        tweet_tokenizer.tokenize(row['Lemmatize']), axis=1)\n",
    "#print(train['tokenized'])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   UserName   Location  \\\n",
      "0  3799      London      \n",
      "1  3800      UK          \n",
      "2  3801      Vagabonds   \n",
      "3  3802      0           \n",
      "4  3803      0           \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                        OriginalTweet  \\\n",
      "0  @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/iFz9FAn2Pa and https://t.co/xX6ghGFzCC and https://t.co/I2NlzdxNo8                                                                                                                                                                                                                      \n",
      "1  advice Talk to your neighbours family to exchange phone numbers create contact list with phone numbers of neighbours schools employer chemist GP set up online shopping accounts if poss adequate supplies of regular meds but not over order                                                                                        \n",
      "2  Coronavirus Australia: Woolworths to give elderly, disabled dedicated shopping hours amid COVID-19 outbreak https://t.co/bInCA9Vp8P                                                                                                                                                                                                  \n",
      "3  My food stock is not the only one which is empty...\\r\\r\\n\\r\\r\\nPLEASE, don't panic, THERE WILL BE ENOUGH FOOD FOR EVERYONE if you do not take more than you need. \\r\\r\\nStay calm, stay safe.\\r\\r\\n\\r\\r\\n#COVID19france #COVID_19 #COVID19 #coronavirus #confinement #Confinementotal #ConfinementGeneral https://t.co/zrlG0Z520j    \n",
      "4  Me, ready to go at supermarket during the #COVID19 outbreak.\\r\\r\\n\\r\\r\\nNot because I'm paranoid, but because my food stock is litteraly empty. The #coronavirus is a serious thing, but please, don't panic. It causes shortage...\\r\\r\\n\\r\\r\\n#CoronavirusFrance #restezchezvous #StayAtHome #confinement https://t.co/usmuaLq72n   \n",
      "\n",
      "   Sentiment  count_words  count_unique_words  count_letters  count_stopwords  \\\n",
      "0  1          8            7                   111            2                 \n",
      "1  2          38           33                  237            11                \n",
      "2  2          14           14                  131            1                 \n",
      "3  2          42           39                  306            19                \n",
      "4  0          40           37                  310            16                \n",
      "\n",
      "   mean_word_len  count_mentions  ...  count_urls  \\\n",
      "0  13.000000      3               ...  3            \n",
      "1  5.263158       0               ...  0            \n",
      "2  8.428571       0               ...  1            \n",
      "3  6.000000       0               ...  1            \n",
      "4  6.525000       0               ...  1            \n",
      "\n",
      "                                                                                                                                                                                                                                                            EditedTweet  \\\n",
      "0  <user> <user> <user> <url> and <url> and <url>                                                                                                                                                                                                                         \n",
      "1  advice talk to your neighbours family to exchange phone numbers create contact list with phone numbers of neighbours schools employer chemist gt set up online shopping accounts if pos adequate supplies of regular mens but not over order                           \n",
      "2  coronavirus australia: woolworths to give elderly, disabled dedicated shopping hours amid covid <number> outbreak <url>                                                                                                                                                \n",
      "3  my food stock is not the only one which is empty.. please, do not panic, here will by enough od or everyone if you do not take more than you need. stay calm, stay safe. <hashtag> <hashtag> <hashtag> <hashtag> <hashtag> <hashtag> <hashtag> <url>                   \n",
      "4  me, ready to go at supermarket during the <hashtag> outbreak. not because i am paranoid, but because my food stock is literary empty. the <hashtag> is a serious thing, but please, do not panic. it causes shortage.. <hashtag> <hashtag> <hashtag> <hashtag> <url>   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      pos_tagged_sent  \\\n",
      "0  [(<user>, JJ), (<user>, NNP), (<user>, NNP), (<url>, NNP), (and, CC), (<url>, NNP), (and, CC), (<url>, VB)]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
      "1  [(advice, NN), (talk, NN), (to, TO), (your, PRP$), (neighbours, NNS), (family, NN), (to, TO), (exchange, VB), (phone, NN), (numbers, NNS), (create, VBP), (contact, JJ), (list, NN), (with, IN), (phone, NN), (numbers, NNS), (of, IN), (neighbours, NNS), (schools, NNS), (employer, VBP), (chemist, JJ), (gt, NN), (set, VBN), (up, RP), (online, JJ), (shopping, NN), (accounts, NNS), (if, IN), (pos, JJ), (adequate, JJ), (supplies, NNS), (of, IN), (regular, JJ), (mens, NNS), (but, CC), (not, RB), (over, IN), (order, NN)]                                                                                                                 \n",
      "2  [(coronavirus, NN), (australia, NNS), (:, :), (woolworths, NNS), (to, TO), (give, VB), (elderly, JJ), (,, ,), (disabled, VBD), (dedicated, VBN), (shopping, NN), (hours, NNS), (amid, IN), (covid, JJ), (<number>, NNP), (outbreak, NN), (<url>, NN)]                                                                                                                                                                                                                                                                                                                                                                                                \n",
      "3  [(my, PRP$), (food, NN), (stock, NN), (is, VBZ), (not, RB), (the, DT), (only, JJ), (one, CD), (which, WDT), (is, VBZ), (empty, JJ), (.., JJ), (please, NN), (,, ,), (do, VBP), (not, RB), (panic, VB), (,, ,), (here, RB), (will, MD), (by, IN), (enough, JJ), (od, NN), (or, CC), (everyone, NN), (if, IN), (you, PRP), (do, VBP), (not, RB), (take, VB), (more, JJR), (than, IN), (you, PRP), (need, VBP), (., .), (stay, VB), (calm, JJ), (,, ,), (stay, JJ), (safe, JJ), (., .), (<hashtag>, JJ), (<hashtag>, JJ), (<hashtag>, NN), (<hashtag>, NNP), (<hashtag>, NNP), (<hashtag>, NNP), (<hashtag>, NNP), (<url>, NN)]                         \n",
      "4  [(me, PRP), (,, ,), (ready, JJ), (to, TO), (go, VB), (at, IN), (supermarket, NN), (during, IN), (the, DT), (<hashtag>, NNP), (outbreak, NN), (., .), (not, RB), (because, IN), (i, NN), (am, VBP), (paranoid, NN), (,, ,), (but, CC), (because, IN), (my, PRP$), (food, NN), (stock, NN), (is, VBZ), (literary, JJ), (empty, RB), (., .), (the, DT), (<hashtag>, NN), (is, VBZ), (a, DT), (serious, JJ), (thing, NN), (,, ,), (but, CC), (please, NN), (,, ,), (do, VBP), (not, RB), (panic, VB), (., .), (it, PRP), (causes, VBZ), (shortage, JJ), (.., JJ), (<hashtag>, NNP), (<hashtag>, NNP), (<hashtag>, NNP), (<hashtag>, NNP), (<url>, NN)]   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Wordnet_tagged_sent  \\\n",
      "0  [(<user>, a), (<user>, n), (<user>, n), (<url>, n), (and, ), (<url>, n), (and, ), (<url>, v)]                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
      "1  [(advice, n), (talk, n), (to, ), (your, ), (neighbours, n), (family, n), (to, ), (exchange, v), (phone, n), (numbers, n), (create, v), (contact, a), (list, n), (with, ), (phone, n), (numbers, n), (of, ), (neighbours, n), (schools, n), (employer, v), (chemist, a), (gt, n), (set, v), (up, r), (online, a), (shopping, n), (accounts, n), (if, ), (pos, a), (adequate, a), (supplies, n), (of, ), (regular, a), (mens, n), (but, ), (not, r), (over, ), (order, n)]                                                                                                \n",
      "2  [(coronavirus, n), (australia, n), (:, ), (woolworths, n), (to, ), (give, v), (elderly, a), (,, ), (disabled, v), (dedicated, v), (shopping, n), (hours, n), (amid, ), (covid, a), (<number>, n), (outbreak, n), (<url>, n)]                                                                                                                                                                                                                                                                                                                                            \n",
      "3  [(my, ), (food, n), (stock, n), (is, v), (not, r), (the, ), (only, a), (one, ), (which, ), (is, v), (empty, a), (.., a), (please, n), (,, ), (do, v), (not, r), (panic, v), (,, ), (here, r), (will, ), (by, ), (enough, a), (od, n), (or, ), (everyone, n), (if, ), (you, ), (do, v), (not, r), (take, v), (more, a), (than, ), (you, ), (need, v), (., ), (stay, v), (calm, a), (,, ), (stay, a), (safe, a), (., ), (<hashtag>, a), (<hashtag>, a), (<hashtag>, n), (<hashtag>, n), (<hashtag>, n), (<hashtag>, n), (<hashtag>, n), (<url>, n)]                       \n",
      "4  [(me, ), (,, ), (ready, a), (to, ), (go, v), (at, ), (supermarket, n), (during, ), (the, ), (<hashtag>, n), (outbreak, n), (., ), (not, r), (because, ), (i, n), (am, v), (paranoid, n), (,, ), (but, ), (because, ), (my, ), (food, n), (stock, n), (is, v), (literary, a), (empty, r), (., ), (the, ), (<hashtag>, n), (is, v), (a, ), (serious, a), (thing, n), (,, ), (but, ), (please, n), (,, ), (do, v), (not, r), (panic, v), (., ), (it, ), (causes, v), (shortage, a), (.., a), (<hashtag>, n), (<hashtag>, n), (<hashtag>, n), (<hashtag>, n), (<url>, n)]   \n",
      "\n",
      "                                                                                                                                                                                                                                                        Preprocessed_sentences  \\\n",
      "0  <user> <user> <user> <url> and <url> and <url>                                                                                                                                                                                                                                \n",
      "1  advice talk to your neighbour family to exchange phone number create contact list with phone number of neighbour school employer chemist gt set up online shopping account if pos adequate supply of regular men but not over order                                           \n",
      "2  coronavirus australia : woolworth to give elderly , disable dedicate shopping hour amid covid <number> outbreak <url>                                                                                                                                                         \n",
      "3  my food stock be not the only one which be empty .. please , do not panic , here will by enough od or everyone if you do not take more than you need . stay calm , stay safe . <hashtag> <hashtag> <hashtag> <hashtag> <hashtag> <hashtag> <hashtag> <url>                    \n",
      "4  me , ready to go at supermarket during the <hashtag> outbreak . not because i be paranoid , but because my food stock be literary empty . the <hashtag> be a serious thing , but please , do not panic . it cause shortage .. <hashtag> <hashtag> <hashtag> <hashtag> <url>   \n",
      "\n",
      "  Adjectives Nouns Others Verbs  Adverbs  \n",
      "0  1          4     2      1     0        \n",
      "1  6          17    9      4     2        \n",
      "2  2          8     4      3     0        \n",
      "3  10         11    16     8     4        \n",
      "4  5          15    20     7     3        \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#new_stopwords = [\\'covid-\\', \\'covid\\', \\'coronavirus\\', \\'``\\']\\nnew_stopwords = [\\'<hashtag>\\', \\'<number>\\', \\'<url>\\', \\'<user>\\']\\nstop_words = stop_words.union(new_stopwords)\\n#stop_words = stop_words - set([\\'not\\'])\\ntrain[\"tokenized\"] = train[\\'tokenized\\'].apply(lambda x: \\n                            [item for item in x if item not in stop_words])\\n\\n#print(Counter(\" \".join(train[\"Tokens_w/ostop\"]).split()).most_common(20))\\n#print(train.loc[[7689]])\\n'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Add new stopwords and remove all of them\n",
    "'''\n",
    "#new_stopwords = ['covid-', 'covid', 'coronavirus', '``']\n",
    "new_stopwords = ['<hashtag>', '<number>', '<url>', '<user>']\n",
    "stop_words = stop_words.union(new_stopwords)\n",
    "#stop_words = stop_words - set(['not'])\n",
    "train[\"tokenized\"] = train['tokenized'].apply(lambda x: \n",
    "                            [item for item in x if item not in stop_words])\n",
    "\n",
    "#print(Counter(\" \".join(train[\"Tokens_w/ostop\"]).split()).most_common(20))\n",
    "#print(train.loc[[7689]])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'train[\"Preprocessed_sentences\"] = train[\"tokenized\"].apply(lambda x:\\n                                                        \" \".join(x))\\nprint(train[\"Preprocessed_sentences\"])'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''train[\"Preprocessed_sentences\"] = train[\"tokenized\"].apply(lambda x:\n",
    "                                                        \" \".join(x))\n",
    "print(train[\"Preprocessed_sentences\"])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove tweets with less than 2 words\n",
    "#train['len_tokens'] = train['tokenized'].apply(lambda x: len(x))\n",
    "#print(train['len_tokens'])\n",
    "#0 = train['len_tokens'].value_counts()[0]\n",
    "#n1 = train['len_tokens'].value_counts()[1]\n",
    "#n2 = train['len_tokens'].value_counts()[2]\n",
    "#print( n1+ n2)\n",
    "\n",
    "#Remove rows that don't contain text after preprocessing\n",
    "train = train[train['Preprocessed_sentences'].str.contains('[A-Za-z]', na=False)]\n",
    "train = train.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save dataset\n",
    "\n",
    "train.to_csv(r'preprocessed_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       UserName                      Location  \\\n",
      "0      3799      London                         \n",
      "1      3800      UK                             \n",
      "2      3801      Vagabonds                      \n",
      "3      3802      0                              \n",
      "4      3803      0                              \n",
      "...     ...     ..                              \n",
      "41152  44951     Wellington City, New Zealand   \n",
      "41153  44952     0                              \n",
      "41154  44953     0                              \n",
      "41155  44954     0                              \n",
      "41156  44955     i love you so much || he/him   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                            OriginalTweet  \\\n",
      "0      @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/iFz9FAn2Pa and https://t.co/xX6ghGFzCC and https://t.co/I2NlzdxNo8                                                                                                                                                                                                                      \n",
      "1      advice Talk to your neighbours family to exchange phone numbers create contact list with phone numbers of neighbours schools employer chemist GP set up online shopping accounts if poss adequate supplies of regular meds but not over order                                                                                        \n",
      "2      Coronavirus Australia: Woolworths to give elderly, disabled dedicated shopping hours amid COVID-19 outbreak https://t.co/bInCA9Vp8P                                                                                                                                                                                                  \n",
      "3      My food stock is not the only one which is empty...\\r\\r\\n\\r\\r\\nPLEASE, don't panic, THERE WILL BE ENOUGH FOOD FOR EVERYONE if you do not take more than you need. \\r\\r\\nStay calm, stay safe.\\r\\r\\n\\r\\r\\n#COVID19france #COVID_19 #COVID19 #coronavirus #confinement #Confinementotal #ConfinementGeneral https://t.co/zrlG0Z520j    \n",
      "4      Me, ready to go at supermarket during the #COVID19 outbreak.\\r\\r\\n\\r\\r\\nNot because I'm paranoid, but because my food stock is litteraly empty. The #coronavirus is a serious thing, but please, don't panic. It causes shortage...\\r\\r\\n\\r\\r\\n#CoronavirusFrance #restezchezvous #StayAtHome #confinement https://t.co/usmuaLq72n   \n",
      "...                                                                                                                                                                                                                                                                                                                                   ...   \n",
      "41152  Airline pilots offering to stock supermarket shelves in #NZ lockdown #COVID-19 https://t.co/cz89uA0HNp                                                                                                                                                                                                                               \n",
      "41153  Response to complaint not provided citing COVID-19 related delays. Yet prompt in rejecting policy before consumer TAT is over. Way to go ?                                                                                                                                                                                           \n",
      "41154  You know itÂs getting tough when @KameronWilds  is rationing toilet paper #coronavirus #toiletpaper @kroger martinsville, help us out!!                                                                                                                                                                                             \n",
      "41155  Is it wrong that the smell of hand sanitizer is starting to turn me on?\\r\\r\\n\\r\\r\\n#coronavirus #COVID19 #coronavirus                                                                                                                                                                                                                \n",
      "41156  @TartiiCat Well new/used Rift S are going for $700.00 on Amazon rn although the normal market price is usually $400.00 . Prices are really crazy right now for vr headsets since HL Alex was announced and it's only been worse with COVID-19. Up to you whethe                                                                      \n",
      "\n",
      "       Sentiment  count_words  count_unique_words  count_letters  \\\n",
      "0      1          8            7                   111             \n",
      "1      2          38           33                  237             \n",
      "2      2          14           14                  131             \n",
      "3      2          42           39                  306             \n",
      "4      0          40           37                  310             \n",
      "...   ..          ..           ..                  ...             \n",
      "41152  1          12           12                  102             \n",
      "41153  0          23           22                  138             \n",
      "41154  2          18           18                  136             \n",
      "41155  1          18           17                  111             \n",
      "41156  0          46           44                  255             \n",
      "\n",
      "       count_stopwords  mean_word_len  count_mentions  ...  count_urls  \\\n",
      "0      2                13.000000      3               ...  3            \n",
      "1      11               5.263158       0               ...  0            \n",
      "2      1                8.428571       0               ...  1            \n",
      "3      19               6.000000       0               ...  1            \n",
      "4      16               6.525000       0               ...  1            \n",
      "...    ..                    ...      ..               ... ..            \n",
      "41152  2                7.583333       0               ...  1            \n",
      "41153  6                5.043478       0               ...  0            \n",
      "41154  3                6.555556       2               ...  0            \n",
      "41155  8                4.944444       0               ...  0            \n",
      "41156  18               4.565217       1               ...  0            \n",
      "\n",
      "                                                                                                                                                                                                                                                                    EditedTweet  \\\n",
      "0      <user> <user> <user> <url> and <url> and <url>                                                                                                                                                                                                                             \n",
      "1      advice talk to your neighbours family to exchange phone numbers create contact list with phone numbers of neighbours schools employer chemist gt set up online shopping accounts if pos adequate supplies of regular mens but not over order                               \n",
      "2      coronavirus australia: woolworths to give elderly, disabled dedicated shopping hours amid covid <number> outbreak <url>                                                                                                                                                    \n",
      "3      my food stock is not the only one which is empty.. please, do not panic, here will by enough od or everyone if you do not take more than you need. stay calm, stay safe. <hashtag> <hashtag> <hashtag> <hashtag> <hashtag> <hashtag> <hashtag> <url>                       \n",
      "4      me, ready to go at supermarket during the <hashtag> outbreak. not because i am paranoid, but because my food stock is literary empty. the <hashtag> is a serious thing, but please, do not panic. it causes shortage.. <hashtag> <hashtag> <hashtag> <hashtag> <url>       \n",
      "...                                                                                                                                                                                                                                                                     ...       \n",
      "41152  airline pilots offering to stock supermarket shelves in <hashtag> lockdown <hashtag> <number> <url>                                                                                                                                                                        \n",
      "41153  response to complaint not provided citing covid <number> related delays. yet prompt in rejecting policy before consumer at is over. way to go ?                                                                                                                            \n",
      "41154  you know its getting tough when <user> is rationing toilet paper <hashtag> <hashtag> <user> martinsville, help us out!!                                                                                                                                                    \n",
      "41155  is it wrong that the smell of hand sanitizer is starting to turn me on? <hashtag> <hashtag> <hashtag>                                                                                                                                                                      \n",
      "41156  <user> well new/used rift s are going for $ <number> on amazon rn although the normal market price is usually $ <number> . prices are really crazy right now for vr headset since l alex was announced and it is only been worse with covid <number> . up to you whether   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                pos_tagged_sent  \\\n",
      "0      [(<user>, JJ), (<user>, NNP), (<user>, NNP), (<url>, NNP), (and, CC), (<url>, NNP), (and, CC), (<url>, VB)]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
      "1      [(advice, NN), (talk, NN), (to, TO), (your, PRP$), (neighbours, NNS), (family, NN), (to, TO), (exchange, VB), (phone, NN), (numbers, NNS), (create, VBP), (contact, JJ), (list, NN), (with, IN), (phone, NN), (numbers, NNS), (of, IN), (neighbours, NNS), (schools, NNS), (employer, VBP), (chemist, JJ), (gt, NN), (set, VBN), (up, RP), (online, JJ), (shopping, NN), (accounts, NNS), (if, IN), (pos, JJ), (adequate, JJ), (supplies, NNS), (of, IN), (regular, JJ), (mens, NNS), (but, CC), (not, RB), (over, IN), (order, NN)]                                                                                                                                       \n",
      "2      [(coronavirus, NN), (australia, NNS), (:, :), (woolworths, NNS), (to, TO), (give, VB), (elderly, JJ), (,, ,), (disabled, VBD), (dedicated, VBN), (shopping, NN), (hours, NNS), (amid, IN), (covid, JJ), (<number>, NNP), (outbreak, NN), (<url>, NN)]                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
      "3      [(my, PRP$), (food, NN), (stock, NN), (is, VBZ), (not, RB), (the, DT), (only, JJ), (one, CD), (which, WDT), (is, VBZ), (empty, JJ), (.., JJ), (please, NN), (,, ,), (do, VBP), (not, RB), (panic, VB), (,, ,), (here, RB), (will, MD), (by, IN), (enough, JJ), (od, NN), (or, CC), (everyone, NN), (if, IN), (you, PRP), (do, VBP), (not, RB), (take, VB), (more, JJR), (than, IN), (you, PRP), (need, VBP), (., .), (stay, VB), (calm, JJ), (,, ,), (stay, JJ), (safe, JJ), (., .), (<hashtag>, JJ), (<hashtag>, JJ), (<hashtag>, NN), (<hashtag>, NNP), (<hashtag>, NNP), (<hashtag>, NNP), (<hashtag>, NNP), (<url>, NN)]                                               \n",
      "4      [(me, PRP), (,, ,), (ready, JJ), (to, TO), (go, VB), (at, IN), (supermarket, NN), (during, IN), (the, DT), (<hashtag>, NNP), (outbreak, NN), (., .), (not, RB), (because, IN), (i, NN), (am, VBP), (paranoid, NN), (,, ,), (but, CC), (because, IN), (my, PRP$), (food, NN), (stock, NN), (is, VBZ), (literary, JJ), (empty, RB), (., .), (the, DT), (<hashtag>, NN), (is, VBZ), (a, DT), (serious, JJ), (thing, NN), (,, ,), (but, CC), (please, NN), (,, ,), (do, VBP), (not, RB), (panic, VB), (., .), (it, PRP), (causes, VBZ), (shortage, JJ), (.., JJ), (<hashtag>, NNP), (<hashtag>, NNP), (<hashtag>, NNP), (<hashtag>, NNP), (<url>, NN)]                         \n",
      "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   ...                         \n",
      "41152  [(airline, NN), (pilots, NNS), (offering, VBG), (to, TO), (stock, NN), (supermarket, NN), (shelves, NNS), (in, IN), (<hashtag>, NNP), (lockdown, JJ), (<hashtag>, NNP), (<number>, NNP), (<url>, NN)]                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
      "41153  [(response, NN), (to, TO), (complaint, VB), (not, RB), (provided, VBN), (citing, VBG), (covid, JJ), (<number>, NNP), (related, JJ), (delays, NNS), (., .), (yet, RB), (prompt, JJ), (in, IN), (rejecting, VBG), (policy, NN), (before, IN), (consumer, NN), (at, IN), (is, VBZ), (over, RB), (., .), (way, NN), (to, TO), (go, VB), (?, .)]                                                                                                                                                                                                                                                                                                                                \n",
      "41154  [(you, PRP), (know, VBP), (its, PRP$), (getting, VBG), (tough, JJ), (when, WRB), (<user>, NN), (is, VBZ), (rationing, VBG), (toilet, JJ), (paper, NN), (<hashtag>, NNP), (<hashtag>, NNP), (<user>, NNP), (martinsville, NNP), (,, ,), (help, VB), (us, PRP), (out, RP), (!, .), (!, .)]                                                                                                                                                                                                                                                                                                                                                                                   \n",
      "41155  [(is, VBZ), (it, PRP), (wrong, JJ), (that, IN), (the, DT), (smell, NN), (of, IN), (hand, NN), (sanitizer, NN), (is, VBZ), (starting, VBG), (to, TO), (turn, VB), (me, PRP), (on, IN), (?, .), (<hashtag>, JJ), (<hashtag>, NN), (<hashtag>, NN)]                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
      "41156  [(<user>, RB), (well, RB), (new, JJ), (/, NNS), (used, VBN), (rift, NN), (s, NN), (are, VBP), (going, VBG), (for, IN), ($, $), (<number>, CD), (on, IN), (amazon, NN), (rn, NN), (although, IN), (the, DT), (normal, JJ), (market, NN), (price, NN), (is, VBZ), (usually, RB), ($, $), (<number>, NN), (., .), (prices, NNS), (are, VBP), (really, RB), (crazy, JJ), (right, NN), (now, RB), (for, IN), (vr, NN), (headset, NN), (since, IN), (l, NN), (alex, NN), (was, VBD), (announced, VBN), (and, CC), (it, PRP), (is, VBZ), (only, RB), (been, VBN), (worse, JJR), (with, IN), (covid, JJ), (<number>, NN), (., .), (up, RP), (to, TO), (you, PRP), (whether, IN)]   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Wordnet_tagged_sent  \\\n",
      "0      [(<user>, a), (<user>, n), (<user>, n), (<url>, n), (and, ), (<url>, n), (and, ), (<url>, v)]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
      "1      [(advice, n), (talk, n), (to, ), (your, ), (neighbours, n), (family, n), (to, ), (exchange, v), (phone, n), (numbers, n), (create, v), (contact, a), (list, n), (with, ), (phone, n), (numbers, n), (of, ), (neighbours, n), (schools, n), (employer, v), (chemist, a), (gt, n), (set, v), (up, r), (online, a), (shopping, n), (accounts, n), (if, ), (pos, a), (adequate, a), (supplies, n), (of, ), (regular, a), (mens, n), (but, ), (not, r), (over, ), (order, n)]                                                                                                                   \n",
      "2      [(coronavirus, n), (australia, n), (:, ), (woolworths, n), (to, ), (give, v), (elderly, a), (,, ), (disabled, v), (dedicated, v), (shopping, n), (hours, n), (amid, ), (covid, a), (<number>, n), (outbreak, n), (<url>, n)]                                                                                                                                                                                                                                                                                                                                                               \n",
      "3      [(my, ), (food, n), (stock, n), (is, v), (not, r), (the, ), (only, a), (one, ), (which, ), (is, v), (empty, a), (.., a), (please, n), (,, ), (do, v), (not, r), (panic, v), (,, ), (here, r), (will, ), (by, ), (enough, a), (od, n), (or, ), (everyone, n), (if, ), (you, ), (do, v), (not, r), (take, v), (more, a), (than, ), (you, ), (need, v), (., ), (stay, v), (calm, a), (,, ), (stay, a), (safe, a), (., ), (<hashtag>, a), (<hashtag>, a), (<hashtag>, n), (<hashtag>, n), (<hashtag>, n), (<hashtag>, n), (<hashtag>, n), (<url>, n)]                                          \n",
      "4      [(me, ), (,, ), (ready, a), (to, ), (go, v), (at, ), (supermarket, n), (during, ), (the, ), (<hashtag>, n), (outbreak, n), (., ), (not, r), (because, ), (i, n), (am, v), (paranoid, n), (,, ), (but, ), (because, ), (my, ), (food, n), (stock, n), (is, v), (literary, a), (empty, r), (., ), (the, ), (<hashtag>, n), (is, v), (a, ), (serious, a), (thing, n), (,, ), (but, ), (please, n), (,, ), (do, v), (not, r), (panic, v), (., ), (it, ), (causes, v), (shortage, a), (.., a), (<hashtag>, n), (<hashtag>, n), (<hashtag>, n), (<hashtag>, n), (<url>, n)]                      \n",
      "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ...                      \n",
      "41152  [(airline, n), (pilots, n), (offering, v), (to, ), (stock, n), (supermarket, n), (shelves, n), (in, ), (<hashtag>, n), (lockdown, a), (<hashtag>, n), (<number>, n), (<url>, n)]                                                                                                                                                                                                                                                                                                                                                                                                           \n",
      "41153  [(response, n), (to, ), (complaint, v), (not, r), (provided, v), (citing, v), (covid, a), (<number>, n), (related, a), (delays, n), (., ), (yet, r), (prompt, a), (in, ), (rejecting, v), (policy, n), (before, ), (consumer, n), (at, ), (is, v), (over, r), (., ), (way, n), (to, ), (go, v), (?, )]                                                                                                                                                                                                                                                                                     \n",
      "41154  [(you, ), (know, v), (its, ), (getting, v), (tough, a), (when, ), (<user>, n), (is, v), (rationing, v), (toilet, a), (paper, n), (<hashtag>, n), (<hashtag>, n), (<user>, n), (martinsville, n), (,, ), (help, v), (us, ), (out, r), (!, ), (!, )]                                                                                                                                                                                                                                                                                                                                         \n",
      "41155  [(is, v), (it, ), (wrong, a), (that, ), (the, ), (smell, n), (of, ), (hand, n), (sanitizer, n), (is, v), (starting, v), (to, ), (turn, v), (me, ), (on, ), (?, ), (<hashtag>, a), (<hashtag>, n), (<hashtag>, n)]                                                                                                                                                                                                                                                                                                                                                                          \n",
      "41156  [(<user>, r), (well, r), (new, a), (/, n), (used, v), (rift, n), (s, n), (are, v), (going, v), (for, ), ($, ), (<number>, ), (on, ), (amazon, n), (rn, n), (although, ), (the, ), (normal, a), (market, n), (price, n), (is, v), (usually, r), ($, ), (<number>, n), (., ), (prices, n), (are, v), (really, r), (crazy, a), (right, n), (now, r), (for, ), (vr, n), (headset, n), (since, ), (l, n), (alex, n), (was, v), (announced, v), (and, ), (it, ), (is, v), (only, r), (been, v), (worse, a), (with, ), (covid, a), (<number>, n), (., ), (up, r), (to, ), (you, ), (whether, )]   \n",
      "\n",
      "                                                                                                                                                                                                                                                            Preprocessed_sentences  \\\n",
      "0      <user> <user> <user> <url> and <url> and <url>                                                                                                                                                                                                                                \n",
      "1      advice talk to your neighbour family to exchange phone number create contact list with phone number of neighbour school employer chemist gt set up online shopping account if pos adequate supply of regular men but not over order                                           \n",
      "2      coronavirus australia : woolworth to give elderly , disable dedicate shopping hour amid covid <number> outbreak <url>                                                                                                                                                         \n",
      "3      my food stock be not the only one which be empty .. please , do not panic , here will by enough od or everyone if you do not take more than you need . stay calm , stay safe . <hashtag> <hashtag> <hashtag> <hashtag> <hashtag> <hashtag> <hashtag> <url>                    \n",
      "4      me , ready to go at supermarket during the <hashtag> outbreak . not because i be paranoid , but because my food stock be literary empty . the <hashtag> be a serious thing , but please , do not panic . it cause shortage .. <hashtag> <hashtag> <hashtag> <hashtag> <url>   \n",
      "...                                                                                                                                                                                                                                                                            ...   \n",
      "41152  airline pilot offer to stock supermarket shelf in <hashtag> lockdown <hashtag> <number> <url>                                                                                                                                                                                 \n",
      "41153  response to complaint not provide cite covid <number> related delay . yet prompt in reject policy before consumer at be over . way to go ?                                                                                                                                    \n",
      "41154  you know its get tough when <user> be ration toilet paper <hashtag> <hashtag> <user> martinsville , help us out ! !                                                                                                                                                           \n",
      "41155  be it wrong that the smell of hand sanitizer be start to turn me on ? <hashtag> <hashtag> <hashtag>                                                                                                                                                                           \n",
      "41156  <user> well new / use rift s be go for $ <number> on amazon rn although the normal market price be usually $ <number> . price be really crazy right now for vr headset since l alex be announce and it be only be bad with covid <number> . up to you whether                 \n",
      "\n",
      "      Adjectives Nouns Others Verbs  Adverbs  \n",
      "0      1          4     2      1     0        \n",
      "1      6          17    9      4     2        \n",
      "2      2          8     4      3     0        \n",
      "3      10         11    16     8     4        \n",
      "4      5          15    20     7     3        \n",
      "...   ..          ..    ..    ..    ..        \n",
      "41152  1          9     2      1     0        \n",
      "41153  3          6     8      6     3        \n",
      "41154  2          6     7      5     1        \n",
      "41155  2          5     8      4     0        \n",
      "41156  5          15    17     9     7        \n",
      "\n",
      "[41157 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
